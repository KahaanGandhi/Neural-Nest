{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ttlP2eUApJr",
        "outputId": "d11facb0-33f5-434f-e186-94920793dc29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalars and vectors traditionally lowercase, while MATRICES and TENSORS are uppercase\n",
        "scalar = torch.tensor(7)\n",
        "scalar.ndim # Give dimensions\n",
        "scalar.item() # Get tensor back as Python integer\n",
        "\n",
        "vector = torch.tensor([7, 7]) # Size is default argument\n",
        "vector.shape\n",
        "\n",
        "MATRIX = torch.tensor([[1, 2],[3, 4]])\n",
        "MATRIX[0] # First \"element\" of matrix = first row\n",
        "\n",
        "TENSOR = torch.tensor([[[1, 2, 3],[4, 5, 6],[7, 7, 9]],\n",
        "                      [[1, 2, 3],[4, 5, 6],[7, 7, 9]]])\n",
        "TENSOR[0,1] == TENSOR[0][1] # Can index both ways"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIdeUPpkBJCr",
        "outputId": "54840fca-92ff-4c2f-d59d-6c9f591826aa"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand(3, 4) # Note ndim = 2, while (1, 3, 4) would be 3\n",
        "random_image_size_tensor = torch.rand(size=(224,224,3)) # Height, width GGB\n",
        "\n",
        "zeros = torch.zeros(size=(3,4))\n",
        "ones = torch.ones(size=(3,4))\n",
        "ones.dtype # Float datatype by default\n",
        "\n",
        "one_to_ten = torch.arange(start=0, end=11, step=1)\n",
        "ten_zeros = torch.zeros_like(input=one_to_ten) # _like mimics shape of input"
      ],
      "metadata": {
        "id": "L9iSJOMuCrfg"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], # Tensors must be right shape...\n",
        "                    dtype = None,\n",
        "                    device = None, # and on right device\n",
        "                    requires_grad = False)\n",
        "\n",
        "float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "int_32_tensor = float_16_tensor.type(torch.int32)\n",
        "\n",
        "int_32_tensor.dtype # Three ways to find common tensor issues\n",
        "int_32_tensor.device\n",
        "int_32_tensor.shape\n",
        "\n",
        "print(f\"Data type of tensor: {int_32_tensor.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW99cDR-HZdF",
        "outputId": "f081b18c-c4e4-495a-a0e8-fd30d77e1128"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data type of tensor: torch.int32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Tensor operations\n",
        "\n",
        "tensor = torch.tensor([1,2,3])\n",
        "tensor += 10\n",
        "torch.mul(tensor, 10)\n",
        "torch.div(tensor, 10)\n",
        "torch.matmul(tensor, tensor) # Rely on built-in PyTorch functions for speed\n",
        "# Inner dimensions must match, and output will have outer dimensions\n",
        "\n",
        "tensorA = torch.tensor(([1,2],\n",
        "           [3,4],\n",
        "           [5,6]))\n",
        "tensorA.T.shape"
      ],
      "metadata": {
        "id": "qH3aT7BaKhd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e14f5e7b-7c88-4c76-8b0a-ab00ac00a0d7"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 738 µs, sys: 0 ns, total: 738 µs\n",
            "Wall time: 2.32 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(0, 100, 10)\n",
        "torch.mean(x.type(torch.float32)) # Can also find min/max, like NumPy\n",
        "torch.argmax(x) # Index of maximum, same for argmin\n",
        "\n",
        "# View shows tensor in different shape, but keeps same memory as original\n",
        "# Stack combines multiple tensors\n",
        "# Squeeze removes all '1' dimensions from tensor\n",
        "# Unsqueeze adds '1' dimension to tensor\n",
        "# Permute returns view of input with swapped dimensions\n",
        "\n",
        "x = torch.arange(1,11)\n",
        "x.reshape(5, 2)\n",
        "x.view(1,10)\n",
        "\n",
        "x_stacked = torch.stack([x, x, x], dim=1)\n",
        "torch.permute(x_stacked, (1,0)) # Another view"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsPKVcAMUJOv",
        "outputId": "caac3c15-6ada-417e-e026-11eca45a5e45"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
              "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
              "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1,10).reshape(1,3,3)\n",
        "x[0, 2, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOLyaTtYi_VR",
        "outputId": "35ed7f69-1c54-4d2c-907b-294d9aea2501"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.arange(1,8)\n",
        "tensor = torch.from_numpy(array) # Note that PyTorch and NumPy have different default types (flaoat32 and float64)\n",
        "\n",
        "tensor2 = torch.ones(7) # PyTorch and NumPy don't share memory\n",
        "tensor2.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lGJqUgdjXcI",
        "outputId": "f1828a6c-8769-485c-e583-88613f10d1b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor_A = torch.rand(3,4)\n",
        "random_tensor_B = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_A == random_tensor_B)\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED) # Only works for the next block of notebook\n",
        "random_tensor_C = torch.rand(3,4)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_D = torch.rand(3,4)\n",
        "print(random_tensor_C == random_tensor_D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KD3UWE3UFEy",
        "outputId": "251fac5b-685d-4448-823d-52533462f1dc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!nvidia-smi #Connected to GPU in Runtime settings\n",
        "torch.cuda.is_available()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Device agnostic code\n",
        "\n",
        "tensor = torch.tensor([1,2,3])\n",
        "tensor.device\n",
        "\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "another_tensor_on_gpu = torch.tensor([6,7,8], device = device)\n",
        "\n",
        "# On a GPU, we cannot convert to NumPy\n",
        "tensor_back_on_CPU = tensor_on_gpu.cpu()\n",
        "tensor_back_on_CPU.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbYEzKuDVbN_",
        "outputId": "6020a318-d190-4fbf-d830-8d339d217293"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb 24 04:37:44 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0              29W /  70W |    105MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-wQ-KKTXXyEK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}